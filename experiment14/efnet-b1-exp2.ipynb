{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:07.444206Z","iopub.status.busy":"2023-11-08T08:02:07.443488Z","iopub.status.idle":"2023-11-08T08:02:21.102164Z","shell.execute_reply":"2023-11-08T08:02:21.101071Z","shell.execute_reply.started":"2023-11-08T08:02:07.444169Z"},"trusted":true},"outputs":[],"source":["!pip install multidict -q #efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:21.105293Z","iopub.status.busy":"2023-11-08T08:02:21.104451Z","iopub.status.idle":"2023-11-08T08:02:28.011751Z","shell.execute_reply":"2023-11-08T08:02:28.010931Z","shell.execute_reply.started":"2023-11-08T08:02:21.105253Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","from PIL import Image\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# from efficientnet_pytorch import EfficientNet\n","from torch.utils.data import Dataset, DataLoader, Sampler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision.models as models\n","\n","from numba import jit\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm.auto import tqdm\n","from multidict import MultiDict\n","\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.013420Z","iopub.status.busy":"2023-11-08T08:02:28.012954Z","iopub.status.idle":"2023-11-08T08:02:28.023973Z","shell.execute_reply":"2023-11-08T08:02:28.023189Z","shell.execute_reply.started":"2023-11-08T08:02:28.013392Z"},"trusted":true},"outputs":[],"source":["DEFAULT_RANDOM_SEED = 42\n","import random\n","import numpy as np\n","\n","\n","def set_all_seeds(seed=DEFAULT_RANDOM_SEED):\n","\n","    # python's seeds\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","    # torch's seeds\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_all_seeds(seed=DEFAULT_RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.026855Z","iopub.status.busy":"2023-11-08T08:02:28.026595Z","iopub.status.idle":"2023-11-08T08:02:28.034252Z","shell.execute_reply":"2023-11-08T08:02:28.033353Z","shell.execute_reply.started":"2023-11-08T08:02:28.026832Z"},"trusted":true},"outputs":[],"source":["# для получения label для каждого файла\n","class_dict = {\n","    'GP': 0, 'G': 1, 'M': 2, 'T': 3, 'clear': 4 # выкинуть один класс - clear\n","}\n","\n","# class_dict = {\n","#     '-20':0, '-25':1, '-30':2, '-35':3\n","# }\n","\n","def get_class_from_path(path, class_dict=class_dict):\n","    for key in class_dict:\n","        if key in path:\n","            return class_dict[key]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.035856Z","iopub.status.busy":"2023-11-08T08:02:28.035461Z","iopub.status.idle":"2023-11-08T08:02:28.243504Z","shell.execute_reply":"2023-11-08T08:02:28.242541Z","shell.execute_reply.started":"2023-11-08T08:02:28.035799Z"},"trusted":true},"outputs":[],"source":["root_dir = '/kaggle/input/lozzzz/all_images'\n","image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n","\n","new_img_files = []\n","labels = []\n","for elem in image_files:\n","    for key in class_dict:\n","        if key in elem:\n","            labels.append(class_dict[key])\n","            new_img_files.append(elem)\n","            break\n","        else:\n","            continue"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.244999Z","iopub.status.busy":"2023-11-08T08:02:28.244685Z","iopub.status.idle":"2023-11-08T08:02:28.253223Z","shell.execute_reply":"2023-11-08T08:02:28.252406Z","shell.execute_reply.started":"2023-11-08T08:02:28.244972Z"},"trusted":true},"outputs":[],"source":["train_paths, valid_paths = train_test_split(new_img_files, random_state=42, shuffle=True, train_size=0.7, stratify=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.254650Z","iopub.status.busy":"2023-11-08T08:02:28.254309Z","iopub.status.idle":"2023-11-08T08:02:28.265565Z","shell.execute_reply":"2023-11-08T08:02:28.264596Z","shell.execute_reply.started":"2023-11-08T08:02:28.254618Z"},"trusted":true},"outputs":[],"source":["labels_train = []\n","for elem in train_paths:\n","    for key in class_dict:\n","        if key in elem:\n","            labels_train.append(class_dict[key])\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.267043Z","iopub.status.busy":"2023-11-08T08:02:28.266680Z","iopub.status.idle":"2023-11-08T08:02:28.334608Z","shell.execute_reply":"2023-11-08T08:02:28.333195Z","shell.execute_reply.started":"2023-11-08T08:02:28.267011Z"},"trusted":true},"outputs":[],"source":["from collections import Counter\n","Counter(labels_train)\n","\n","class_counts = [106, 104, 89, 99, 59]\n","class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n","class_weights /= class_weights.sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.336726Z","iopub.status.busy":"2023-11-08T08:02:28.336333Z","iopub.status.idle":"2023-11-08T08:02:28.458559Z","shell.execute_reply":"2023-11-08T08:02:28.457623Z","shell.execute_reply.started":"2023-11-08T08:02:28.336689Z"},"trusted":true},"outputs":[],"source":["@jit(nopython=True)\n","def cut_fragments(image, mode, n, size):\n","    height, width = image.shape[:2]\n","    fragments = []\n","    if mode == 'central':\n","        for i in range(n):\n","            for j in range(n):\n","                left = (width / n) * i\n","                upper = (height / n) * j\n","                right = left + size\n","                lower = upper + size\n","                fragment = image[int(upper):int(lower), int(left):int(right)]\n","                fragments.append(fragment)\n","    elif mode == 'random':\n","        for _ in range(n):\n","            left = random.randint(0, width - size)\n","            upper = random.randint(0, height - size)\n","            right = left + size\n","            lower = upper + size\n","            fragment = image[int(upper):int(lower), int(left):int(right)]\n","            fragments.append(fragment)\n","    return fragments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.462524Z","iopub.status.busy":"2023-11-08T08:02:28.461844Z","iopub.status.idle":"2023-11-08T08:02:28.469846Z","shell.execute_reply":"2023-11-08T08:02:28.468981Z","shell.execute_reply.started":"2023-11-08T08:02:28.462490Z"},"trusted":true},"outputs":[],"source":["# обрезаем хвосты и заменяем их на 0 и 1\n","def cut_percentiles(image):\n","    q1 = np.percentile(image, 1)\n","    q99 = np.percentile(image, 99)\n","\n","    image[image < q1] = 0\n","    image[image > q99] = 1\n","    return image\n","\n","def bilateral_filter(image):\n","    return cv2.bilateralFilter(image, 9, 75, 75)\n","\n","# применение bilateral filter\n","def apply_bilateral_filter_to_normalized(image):\n","    image_8bit = (image * 255).astype(np.uint8)\n","    return bilateral_filter(image_8bit) / 255.0\n","\n","def median_filter(image):\n","    return cv2.medianBlur(image, 5)\n","\n","def apply_median_filter_to_normalized(image):\n","    image_8bit = (image * 255).astype(np.uint8)\n","    return median_filter(image_8bit) / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.471936Z","iopub.status.busy":"2023-11-08T08:02:28.471160Z","iopub.status.idle":"2023-11-08T08:02:28.483103Z","shell.execute_reply":"2023-11-08T08:02:28.482204Z","shell.execute_reply.started":"2023-11-08T08:02:28.471908Z"},"trusted":true},"outputs":[],"source":["class LozDataset(Dataset):\n","    def __init__(self, root_dir, image_files, mode: str = 'central', n: int = 3, size: int = 224, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_files = [os.path.join(self.root_dir, image_file) for image_file in image_files]\n","        self.mode = mode\n","        self.n = n\n","        self.size = size\n","        \n","    def __len__(self):\n","        if self.mode == 'central':  \n","            return len(self.image_files) * self.n * self.n\n","        else:\n","            return len(self.image_files) * self.n\n","\n","    def __getitem__(self, idx):\n","        if self.mode:\n","            fragments_per_image = self.n * self.n\n","        else:\n","            fragments_per_image = self.n\n","\n","        image_idx = idx // fragments_per_image\n","        fragment_idx = idx % fragments_per_image\n","        \n","        img_name = self.image_files[image_idx]\n","        image = Image.open(img_name).convert('L')\n","        image_np = np.array(image)\n","        \n","        fragments = cut_fragments(image=image_np, mode=self.mode, n=self.n, size=self.size)\n","        fragment = fragments[fragment_idx]\n","        \n","        # нормализуем фрагмент\n","        max_value = np.max(fragment)\n","        fragment = fragment / max_value\n","#         fragment = cut_percentiles(fragment)\n","#         fragment = apply_bilateral_filter_to_normalized(fragment)\n","        \n","        if self.transform:\n","            fragment = self.transform(image=fragment)['image']\n","        \n","        label = get_class_from_path(img_name)\n","        image_t = torch.tensor(fragment, dtype=torch.float32)\n","\n","        return image_t, img_name, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.484728Z","iopub.status.busy":"2023-11-08T08:02:28.484317Z","iopub.status.idle":"2023-11-08T08:02:28.498728Z","shell.execute_reply":"2023-11-08T08:02:28.497658Z","shell.execute_reply.started":"2023-11-08T08:02:28.484673Z"},"trusted":true},"outputs":[],"source":["# соль и перец\n","class SaltAndPepper(A.ImageOnlyTransform):\n","    def __init__(self, p=1., salt_ratio=0.5, amount=0.0008, always_apply=True):\n","        super().__init__(always_apply, p)\n","        self.salt_ratio = salt_ratio\n","        self.amount = amount\n","\n","    def apply(self, image, **params):\n","        image_copy = np.copy(image)  # создание копии изображения\n","\n","        num_salt = np.ceil(self.amount * image.size * self.salt_ratio)\n","        coords_salt = [np.random.randint(0, i - 1, int(num_salt)) for i in image_copy.shape]\n","        image_copy[coords_salt[0], coords_salt[1]] = 1\n","\n","        num_pepper = np.ceil(self.amount * image.size * (1.0 - self.salt_ratio))\n","        coords_pepper = [np.random.randint(0, i - 1, int(num_pepper)) for i in image_copy.shape]\n","        image_copy[coords_pepper[0], coords_pepper[1]] = 0\n","\n","        return image_copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:28.500497Z","iopub.status.busy":"2023-11-08T08:02:28.500232Z","iopub.status.idle":"2023-11-08T08:02:28.511993Z","shell.execute_reply":"2023-11-08T08:02:28.511165Z","shell.execute_reply.started":"2023-11-08T08:02:28.500474Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=.3),\n","#     A.RandomBrightnessContrast(p=1, contrast_limit=(.2), brightness_by_max=True, brightness_limit=(.2)),\n","    A.Rotate(limit=30, p=.3),\n","#     A.GaussianBlur(p=1, blur_limit=(1,3)),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=200, max_height=3, max_width=3),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=0, max_height=3, max_width=3),\n","#     A.GaussNoise(var_limit=(10.0), p=1), #белый шум\n","    SaltAndPepper(salt_ratio=0.4),\n","#     A.ElasticTransform(alpha=2, sigma=20, alpha_affine=10, p=.4),\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:41.516370Z","iopub.status.busy":"2023-11-08T08:02:41.515501Z","iopub.status.idle":"2023-11-08T08:02:41.522424Z","shell.execute_reply":"2023-11-08T08:02:41.521285Z","shell.execute_reply.started":"2023-11-08T08:02:41.516336Z"},"trusted":true},"outputs":[],"source":["root_dir = '/kaggle/input/lozzzz/all_images'\n","train_dataset = LozDataset(root_dir, train_paths, transform=train_transform, size=240, n=5)\n","valid_dataset = LozDataset(root_dir, valid_paths, size=240, n=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:43.744526Z","iopub.status.busy":"2023-11-08T08:02:43.743809Z","iopub.status.idle":"2023-11-08T08:02:43.749675Z","shell.execute_reply":"2023-11-08T08:02:43.748691Z","shell.execute_reply.started":"2023-11-08T08:02:43.744491Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, drop_last=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=2, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:45.895420Z","iopub.status.busy":"2023-11-08T08:02:45.895041Z","iopub.status.idle":"2023-11-08T08:02:49.779762Z","shell.execute_reply":"2023-11-08T08:02:49.778941Z","shell.execute_reply.started":"2023-11-08T08:02:45.895387Z"},"trusted":true},"outputs":[],"source":["NUM_CLASSES = len(class_dict)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# mobilenet_v2_model = models.mobilenet_v2(pretrained=True)\n","# mobilenet_v2_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","# mobilenet_v2_model.classifier[1] = nn.Linear(mobilenet_v2_model.last_channel, NUM_CLASSES)\n","# mobilenet_v2_model = mobilenet_v2_model.to(device)\n","mobilenet_v2_model = models.efficientnet_b1(pretrained=True)\n","num_classes = len(class_dict) \n","first_conv_layer = mobilenet_v2_model.features[0][0]\n","mobilenet_v2_model.features[0][0] = torch.nn.Conv2d(1, first_conv_layer.out_channels, \n","                                      kernel_size=first_conv_layer.kernel_size, \n","                                      stride=first_conv_layer.stride, \n","                                      padding=first_conv_layer.padding, bias=False)\n","mobilenet_v2_model.classifier[1] = torch.nn.Linear(mobilenet_v2_model.classifier[1].in_features, num_classes)\n","mobilenet_v2_model = mobilenet_v2_model.to(device)\n","\n","if torch.cuda.device_count() > 1:\n","    mobilenet_v2_model = torch.nn.DataParallel(mobilenet_v2_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:52.921779Z","iopub.status.busy":"2023-11-08T08:02:52.921433Z","iopub.status.idle":"2023-11-08T08:02:52.930333Z","shell.execute_reply":"2023-11-08T08:02:52.929496Z","shell.execute_reply.started":"2023-11-08T08:02:52.921750Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","# criterion = FocalLoss(alpha=.8)\n","\n","optimizer = torch.optim.AdamW(mobilenet_v2_model.parameters())\n","# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.6)\n","\n","milestones = [12, 15, 26]\n","gamma = 0.3\n","exp_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:02:55.263888Z","iopub.status.busy":"2023-11-08T08:02:55.263070Z","iopub.status.idle":"2023-11-08T08:03:31.707643Z","shell.execute_reply":"2023-11-08T08:03:31.706756Z","shell.execute_reply.started":"2023-11-08T08:02:55.263855Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"first_expirement\",\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","        \"architecture\": \"efficientnet_b1\",\n","        \"dataset\": \"lozz\",\n","        \"epochs\": 30,\n","        \"fragments\": 25,\n","        \"central\": True,\n","        \"batch_size\": 16,\n","        \"classes\": 5,\n","        \"size\": 240,\n","        \"preprocessing\": \"normalizing\",\n","        \"augmentations\": \"\"\"\n","                        A.HorizontalFlip(p=.3),\n","                    #     A.RandomBrightnessContrast(p=1, contrast_limit=(.2), brightness_by_max=True, brightness_limit=(.2)),\n","                        A.Rotate(limit=30, p=.3),\n","                    #     A.GaussianBlur(p=1, blur_limit=(1,3)),\n","                    #     A.CoarseDropout(max_holes=6, p=1., fill_value=200, max_height=3, max_width=3),\n","                    #     A.CoarseDropout(max_holes=6, p=1., fill_value=0, max_height=3, max_width=3),\n","                    #     A.GaussNoise(var_limit=(10.0), p=1), #белый шум\n","                        SaltAndPepper(salt_ratio=.4),\n","                    #    A.ElasticTransform(alpha=2, sigma=20, alpha_affine=10, p=.4),\n","                        \"\"\",\n","        \"optimizer\": 'torch.optim.AdamW(mobilenet_v2_model.parameters())',\n","        \"criterion\": 'nn.CrossEntropyLoss(weight=class_weights.to(device))',\n","        \"sheduler\": 'torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)'\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T08:03:34.664925Z","iopub.status.busy":"2023-11-08T08:03:34.664425Z","iopub.status.idle":"2023-11-08T08:03:34.689108Z","shell.execute_reply":"2023-11-08T08:03:34.688033Z","shell.execute_reply.started":"2023-11-08T08:03:34.664868Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","train_acc = []\n","test_loss = []\n","test_acc = []\n","\n","def train_and_validate(epoch):\n","                                                ### train\n","    print(f'EPOCH: {epoch + 1}')\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    mobilenet_v2_model.train()\n","    for batch_idx, (data, name, target) in tqdm(enumerate(train_dataloader)):\n","        target = target.type(torch.LongTensor)\n","        \n","        data = data.unsqueeze(1)\n","        data, target = data.to(device).float(), target.to(device)\n","        optimizer.zero_grad()\n","        outputs = mobilenet_v2_model(data)\n","    \n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        preds = outputs.argmax(dim=1)\n","        running_acc += (preds == target).float().mean().item()\n","        \n","        if batch_idx % 100 == 0:\n","            random_img = data.cpu().numpy()[np.random.randint(data.size(0))][0]\n","            plt.imshow(random_img, cmap='gray')\n","            plt.title(\"Random Image from Batch\")\n","            plt.axis('off')\n","            plt.show()\n","    \n","    train_loss.append(running_loss / len(train_dataloader))\n","    train_acc.append(running_acc / len(train_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Train Loss: {train_loss[-1]:.3f}, Train Acc: {train_acc[-1]:.3f}, \")\n","    exp_lr_scheduler.step()\n","    \n","                                                ### validate\n","\n","    mobilenet_v2_model.eval()\n","    all_preds = [] \n","    all_targets = [] \n","    with torch.no_grad():\n","        running_acc = 0.0\n","        for batch_idx, (data, name, target) in enumerate(valid_dataloader):\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device), target.to(device)\n","            data = data.float()\n","\n","            outputs = mobilenet_v2_model(data)\n","\n","            loss = criterion(outputs, target)\n","            running_loss += loss.item()\n","            preds = outputs.argmax(dim=1)\n","            running_acc += (preds == target).float().mean().item()\n","\n","            all_targets.extend(target.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","            \n","\n","    test_loss.append(running_loss / len(valid_dataloader))\n","    test_acc.append(running_acc / len(valid_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Valid Loss: {test_loss[-1]:.3f}, Valid Acc: {test_acc[-1]:.3f}, \")\n","    \n","    cm = confusion_matrix(all_targets, all_preds)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","    disp.plot()\n","    plt.show()\n","    \n","    wandb.log({\"train_acc\": train_acc[-1], \"train_loss\": train_loss[-1], \"valid_acc\": test_acc[-1], \"valid_loss\": test_loss[-1]})\n","    return train_loss, train_acc, test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-11-08T08:03:37.972748Z","iopub.status.busy":"2023-11-08T08:03:37.971788Z","iopub.status.idle":"2023-11-08T10:46:06.327034Z","shell.execute_reply":"2023-11-08T10:46:06.325961Z","shell.execute_reply.started":"2023-11-08T08:03:37.972715Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["best_loss = float('inf')\n","epochs_without_improvement = 0\n","early_stopping_threshold = 5\n","\n","for epoch in range(30):\n","    train_loss, train_acc, test_loss, test_acc = train_and_validate(epoch)\n","    \n","    if test_loss[-1] < best_loss:\n","        best_loss = test_loss[-1]\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","        \n","    if epochs_without_improvement >= early_stopping_threshold:\n","        print(\"Early stopping triggered after {} epochs without improvement.\".format(epochs_without_improvement))\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T10:46:11.965167Z","iopub.status.busy":"2023-11-08T10:46:11.964751Z","iopub.status.idle":"2023-11-08T10:46:17.713997Z","shell.execute_reply":"2023-11-08T10:46:17.713076Z","shell.execute_reply.started":"2023-11-08T10:46:11.965133Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Оценка результатов для полных картинок"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T10:46:17.715853Z","iopub.status.busy":"2023-11-08T10:46:17.715555Z","iopub.status.idle":"2023-11-08T10:47:49.626230Z","shell.execute_reply":"2023-11-08T10:47:49.624819Z","shell.execute_reply.started":"2023-11-08T10:46:17.715826Z"},"trusted":true},"outputs":[],"source":["def get_predictions():\n","    \"\"\"\n","    возвращает MultiDict, в котором каждому названию картинки соответствует несколько значений\n","    это предсказания для фрагментов данного изображения\n","    для каждого изображения будет строчек столько, на сколько фрагментов разбиваем это изображение\n","    \"\"\"\n","    fragments = MultiDict()\n","    mobilenet_v2_model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (data, name, target) in enumerate(valid_dataloader):\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device), target.to(device)\n","            data = data.float()\n","            outputs = mobilenet_v2_model.to(device)(data)\n","            preds = outputs.argmax(dim=1)\n","            \n","            for n, pred in zip(name, preds):\n","                fragments.add(n, pred.item())\n","    return fragments\n","fragments = get_predictions()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T10:47:49.628340Z","iopub.status.busy":"2023-11-08T10:47:49.627885Z","iopub.status.idle":"2023-11-08T10:47:49.641339Z","shell.execute_reply":"2023-11-08T10:47:49.640136Z","shell.execute_reply.started":"2023-11-08T10:47:49.628301Z"},"trusted":true},"outputs":[],"source":["from collections import Counter\n","\n","def most_common_class_per_key(multidict):\n","    \"\"\"\n","    Получает MultiDict на вход и подсчитывает для одного изображения самый частый предсказанный класс\n","    Выдает словарь, с названием изображения и самым частым классом\n","    \"\"\"\n","    result = {}\n","    keys = set(multidict.keys())\n","    \n","    for key in keys:\n","        values = multidict.getall(key)\n","        count = Counter(values)  \n","        most_common_class, _ = count.most_common(1)[0]\n","        result[key] = most_common_class\n","        \n","    return result\n","\n","result = most_common_class_per_key(fragments)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T10:47:49.644102Z","iopub.status.busy":"2023-11-08T10:47:49.643729Z","iopub.status.idle":"2023-11-08T10:47:49.661399Z","shell.execute_reply":"2023-11-08T10:47:49.660423Z","shell.execute_reply.started":"2023-11-08T10:47:49.644064Z"},"trusted":true},"outputs":[],"source":["def accuracy_full(result: dict):  \n","    \"\"\"\n","    result - словарь, где каждому пути к изображению сопоставляется самый часто встречаемый класс\n","    return accuracy - между предсказанными значениями и истинными\n","    \"\"\"\n","    true_val = 0.0\n","    for key, value in result.items():\n","        y_true = get_class_from_path(f\"'{key}'\")\n","        y_pred = result[key]\n","        if y_true == y_pred:\n","            true_val += 1\n","    accuracy = round(true_val / len(result) * 100, 3)\n","    return f\"Accuracy для полных картинок: {accuracy}%\"\n","accuracy_full(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
