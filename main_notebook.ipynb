{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:40:39.832417Z","iopub.status.busy":"2024-04-18T10:40:39.831757Z","iopub.status.idle":"2024-04-18T10:40:52.992308Z","shell.execute_reply":"2024-04-18T10:40:52.991095Z","shell.execute_reply.started":"2024-04-18T10:40:39.832386Z"},"trusted":true},"outputs":[],"source":["# Установка дополнительных заввисимостей\n","# !pip install multidict -q"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:40:52.994824Z","iopub.status.busy":"2024-04-18T10:40:52.994506Z","iopub.status.idle":"2024-04-18T10:41:02.334878Z","shell.execute_reply":"2024-04-18T10:41:02.333826Z","shell.execute_reply.started":"2024-04-18T10:40:52.994794Z"},"trusted":true},"outputs":[],"source":["# Импорт необходимых библиотек\n","import pandas as pd\n","import numpy as np\n","import os\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from PIL import Image\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from torch.utils.data import Dataset, DataLoader, Sampler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision.models as models\n","from sklearn.model_selection import train_test_split\n","\n","import cv2\n","\n","from tqdm.auto import tqdm\n","\n","from numba import jit\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","from multidict import MultiDict\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.336932Z","iopub.status.busy":"2024-04-18T10:41:02.336301Z","iopub.status.idle":"2024-04-18T10:41:02.345635Z","shell.execute_reply":"2024-04-18T10:41:02.344925Z","shell.execute_reply.started":"2024-04-18T10:41:02.336894Z"},"trusted":true},"outputs":[],"source":["# Зафиксируем сиды для воспроизводимости\n","DEFAULT_RANDOM_SEED = 42\n","import random\n","\n","def set_all_seeds(seed=DEFAULT_RANDOM_SEED):\n","\n","    # python's seeds\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","    # torch's seeds\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_all_seeds(seed=DEFAULT_RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.348207Z","iopub.status.busy":"2024-04-18T10:41:02.347894Z","iopub.status.idle":"2024-04-18T10:41:02.367521Z","shell.execute_reply":"2024-04-18T10:41:02.366575Z","shell.execute_reply.started":"2024-04-18T10:41:02.348171Z"},"trusted":true},"outputs":[],"source":["# Класс для создания тренировочной и тестовой выборки\n","\n","from typing import List, Tuple\n","\n","class FullDataset():\n","    def __init__(self, path_kylberg: str, path_loz: str, classes_from_loz: List[str] = None) -> pd.DataFrame:\n","        self.path_kylberg = path_kylberg\n","        self.path_loz = path_loz\n","        self.classes_from_loz = classes_from_loz\n","        \n","    def create_kylberg(self) -> pd.DataFrame:\n","        folder_names = [name for name in os.listdir(self.path_kylberg) if os.path.isdir(os.path.join(self.path_kylberg, name))]\n","        \n","        label2id_kylberg = {} \n","        for ind, name in enumerate(folder_names):\n","            label2id_kylberg[name] = ind\n","        \n","        root_path = Path(self.path_kylberg)\n","        data = {'class_name': [], 'image_name': []}\n","        \n","        for class_folder in tqdm(root_path.iterdir()):\n","            if class_folder.is_dir():\n","                for image_file in class_folder.iterdir():\n","                    if image_file.is_file(): \n","                        data['class_name'].append(class_folder.name)\n","                        data['image_name'].append(image_file.name)\n","        \n","        df = pd.DataFrame(data)\n","        df['class'] = df['class_name'].map(label2id_kylberg)\n","#         df = df.drop(['class_name'], axis=1)\n","        df['dataset_type'] = 'kylberg'\n","        train_kylberg, test_kylberg = train_test_split(df, random_state=42, shuffle=True, test_size=.3)\n","        \n","        train_kylberg = train_kylberg.reset_index(drop=True)\n","        test_kylberg = test_kylberg.reset_index(drop=True)\n","        \n","        return train_kylberg, test_kylberg\n","    \n","    def create_loz(self) -> pd.DataFrame:\n","        label2id_lozz = {\n","            'GP': 0, 'G': 1, 'M': 2, 'T': 3, 'clear': 4\n","        }\n","        \n","        root_path = Path(self.path_loz)\n","        data = {'class_name': [], 'subfolder_name': [], 'image_name': []}\n","\n","        for class_folder in root_path.iterdir():\n","            if class_folder.is_dir():\n","                for subfolder in class_folder.iterdir():\n","                    if subfolder.is_dir():\n","                        for image_file in subfolder.iterdir():\n","                            if image_file.is_file():\n","                                data['class_name'].append(class_folder.name)\n","                                data['subfolder_name'].append(subfolder.name)\n","                                data['image_name'].append(image_file.name)\n","        \n","        df = pd.DataFrame(data)\n","#         df['class'] = df['class_name'] + '_' + df['subfolder_name']\n","#         label2id_lozz = {label: ind for ind, label in enumerate(df['class'].unique().tolist())}\n","#         df['class'] = df['class'].map(label2id_lozz)\n","        df['class'] = df['subfolder_name'].map(label2id_lozz)\n","        df['dataset_type'] = 'loz'\n","        \n","#         df = df.loc[df['subfolder_name'].isin(self.classes_from_loz)]\n","        train_loz, test_loz = train_test_split(df, random_state=42, shuffle=True, test_size=.3, stratify=df['class'])\n","        \n","        train_loz = train_loz.reset_index(drop=True)\n","        test_loz = test_loz.reset_index(drop=True)\n","        \n","        return train_loz, test_loz, label2id_lozz\n","    \n","    def create_full_df(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n","        train_kylberg, test_kylberg = self.create_kylberg()\n","        train_loz, test_loz = self.create_loz()\n","        train = pd.concat([train_kylberg, train_loz])\n","        train = train.reset_index(drop=True)\n","        train.loc[train['dataset_type'] == 'loz', 'class'] += 28\n","        test_loz.loc[test_loz['dataset_type'] == 'loz', 'class'] += 28\n","        \n","        return train, test_kylberg, test_loz\n","    \n","    def split_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n","        return self.create_full_df()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.369205Z","iopub.status.busy":"2024-04-18T10:41:02.368823Z","iopub.status.idle":"2024-04-18T10:41:02.460472Z","shell.execute_reply":"2024-04-18T10:41:02.459804Z","shell.execute_reply.started":"2024-04-18T10:41:02.369174Z"},"trusted":true},"outputs":[],"source":["# Функция 2 вида для разрезания на фрагменты\n","\n","@jit(nopython=True)\n","def cut_fragments(image, mode, n, size):\n","    height, width = image.shape[:2]\n","    fragments = []\n","    if mode == 'central':\n","        for i in range(n):\n","            for j in range(n):\n","                left = (width / n) * i\n","                upper = (height / n) * j\n","                right = left + size\n","                lower = upper + size\n","                fragment = image[int(upper):int(lower), int(left):int(right)]\n","                fragments.append(fragment)\n","    elif mode == 'random':\n","        for _ in range(n):\n","            left = random.randint(0, width - size)\n","            upper = random.randint(0, height - size)\n","            right = left + size\n","            lower = upper + size\n","            fragment = image[int(upper):int(lower), int(left):int(right)]\n","            fragments.append(fragment)\n","    return fragments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.461807Z","iopub.status.busy":"2024-04-18T10:41:02.461532Z","iopub.status.idle":"2024-04-18T10:41:02.476183Z","shell.execute_reply":"2024-04-18T10:41:02.475283Z","shell.execute_reply.started":"2024-04-18T10:41:02.461785Z"},"trusted":true},"outputs":[],"source":["# Класс для итерации по выборке\n","\n","class TorchDataset(Dataset):\n","    def __init__(self, df:pd.DataFrame, transform_kylberg = None, transform_loz = None,\n","                 mode: str = 'central', n: int = 3, size: int = 224,\n","                 kylberg_path: str = '/kaggle/input/kylberg-texture-dataset', \n","                 loz_path: str = '/kaggle/input/lozzzz/dataset-loz2/dataset2'\n","            ):\n","        \n","        self.df = df\n","        self.mode = mode\n","        self.n = n\n","        self.size = size\n","        self.kylberg_path = kylberg_path\n","        self.loz_path = loz_path\n","        self.transform_kylberg = transform_kylberg\n","        self.transform_loz = transform_loz\n","        self.prepare_dataset()\n","\n","    def prepare_dataset(self):\n","        # Вычисляем общее количество элементов для каждого типа данных и сохраняем в новый столбец\n","        self.df['total_items'] = self.df.apply(lambda x: self.n*self.n if x['dataset_type'] == 'loz' and self.mode == 'central' else self.n if x['dataset_type'] == 'loz' and self.mode == 'random' else 1, axis=1)\n","        # Создаем кумулятивную сумму для определения начального индекса для каждой строки\n","        self.df['cumsum'] = self.df['total_items'].cumsum() - self.df['total_items']\n","        \n","    def __len__(self):\n","        # Общее количество элементов равно кумулятивной сумме последнего элемента\n","        return self.df['cumsum'].iloc[-1] + self.df['total_items'].iloc[-1]\n","\n","    def __getitem__(self, idx):\n","        row = self.df[self.df['cumsum'] <= idx].iloc[-1]\n","        local_idx = idx - row['cumsum']\n","        \n","        if row['dataset_type'] == 'kylberg':\n","            image_path = os.path.join(self.kylberg_path, row['class_name'], row['image_name'])\n","            image = Image.open(image_path).convert('L')\n","        else:  # 'loz'\n","            img_path = os.path.join(self.loz_path, row['class_name'], row.get('subfolder_name', ''), row['image_name'])\n","            image = Image.open(img_path).convert('L')\n","            fragments = cut_fragments(np.array(image), self.mode, self.n, self.size)\n","            image = Image.fromarray(fragments[local_idx])\n","#         image_np = np.array(image, dtype=np.float32)\n","        image_np = np.array(image, dtype=np.float32) / 255.0\n","        if row['dataset_type'] == 'kylberg' and self.transform_kylberg:\n","            image_np = self.transform_kylberg(image=image_np)['image']\n","        elif row['dataset_type'] == 'loz' and self.transform_loz:\n","            image_np = self.transform_loz(image=image_np)['image']\n","\n","        image_t = torch.tensor(image_np, dtype=torch.float32)\n","        label = row['class']\n","\n","        return image_t, row['image_name'], label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.477601Z","iopub.status.busy":"2024-04-18T10:41:02.477327Z","iopub.status.idle":"2024-04-18T10:41:02.488303Z","shell.execute_reply":"2024-04-18T10:41:02.487462Z","shell.execute_reply.started":"2024-04-18T10:41:02.477578Z"},"trusted":true},"outputs":[],"source":["# Добавление шума Соль и Перец\n","\n","class SaltAndPepper(A.ImageOnlyTransform):\n","    def __init__(self, salt_ratio=0.5, amount=0.0008, p=0.5):\n","        super().__init__(p=p) \n","        self.salt_ratio = salt_ratio\n","        self.amount = amount\n","\n","    def apply(self, image, **params):\n","        image_copy = np.copy(image)\n","\n","        num_salt = np.ceil(self.amount * image.size * self.salt_ratio)\n","        coords_salt = [np.random.randint(0, i - 1, int(num_salt)) for i in image_copy.shape]\n","        image_copy[coords_salt[0], coords_salt[1]] = 1\n","\n","        num_pepper = np.ceil(self.amount * image.size * (1.0 - self.salt_ratio))\n","        coords_pepper = [np.random.randint(0, i - 1, int(num_pepper)) for i in image_copy.shape]\n","        image_copy[coords_pepper[0], coords_pepper[1]] = 0\n","\n","        return image_copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.489588Z","iopub.status.busy":"2024-04-18T10:41:02.489301Z","iopub.status.idle":"2024-04-18T10:41:02.499988Z","shell.execute_reply":"2024-04-18T10:41:02.499166Z","shell.execute_reply.started":"2024-04-18T10:41:02.489564Z"},"trusted":true},"outputs":[],"source":["# Применяемые искажения\n","\n","transform_loz = A.Compose([\n","    A.HorizontalFlip(p=.3),\n","    A.Rotate(limit=30, p=.3),\n","    SaltAndPepper(salt_ratio=0.4, p=1.),\n","#     A.Resize(224, 224, p=1.)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.501254Z","iopub.status.busy":"2024-04-18T10:41:02.501004Z","iopub.status.idle":"2024-04-18T10:41:02.885484Z","shell.execute_reply":"2024-04-18T10:41:02.884759Z","shell.execute_reply.started":"2024-04-18T10:41:02.501233Z"},"trusted":true},"outputs":[],"source":["full_dataset = FullDataset(\n","                path_kylberg = '/kaggle/input/kylberg-texture-dataset',\n","                path_loz = '/kaggle/input/lozzzz/dataset-loz2/dataset2',\n","            )\n","\n","train_loz, valid_loz, label2id_loz = full_dataset.create_loz()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:02.888401Z","iopub.status.busy":"2024-04-18T10:41:02.888124Z","iopub.status.idle":"2024-04-18T10:41:02.904180Z","shell.execute_reply":"2024-04-18T10:41:02.903296Z","shell.execute_reply.started":"2024-04-18T10:41:02.888378Z"},"trusted":true},"outputs":[],"source":["train_dataset_loz = TorchDataset(train_loz, transform_loz=transform_loz)\n","valid_dataset_loz = TorchDataset(valid_loz)\n","train_dataloader_loz = DataLoader(train_dataset_loz, batch_size=32, shuffle=True, drop_last=False)\n","valid_dataloader_loz = DataLoader(valid_dataset_loz, batch_size=32, shuffle=False, drop_last=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:06.159482Z","iopub.status.busy":"2024-04-18T10:41:06.159200Z","iopub.status.idle":"2024-04-18T10:41:06.765854Z","shell.execute_reply":"2024-04-18T10:41:06.764945Z","shell.execute_reply.started":"2024-04-18T10:41:06.159457Z"},"trusted":true},"outputs":[],"source":["from collections import OrderedDict\n","\n","NUM_CLASSES = len(label2id_loz)\n","\n","repo_id = 'danzzzll/mobilenet-v2-textures'\n","filename = 'mob-v2_trainKylberg_finetuneLoz-2class.pth'\n","\n","class LozzModel():\n","    def __init__(self, model_name: str, kylberg_on: bool = False, num_classes: int = 5, repo_id: str = None, filename: str = None):\n","        self.model_name = model_name\n","        self.kylberg_on = kylberg_on\n","        self.num_classes = num_classes\n","        self.repo_id = repo_id\n","        self.filename = filename\n","        \n","    def load_model(self):\n","        \n","        if self.model_name == 'mobilenet-v2':\n","            model = models.mobilenet_v2(pretrained=True)\n","            model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            model.classifier[1] = nn.Linear(model.last_channel, self.num_classes)\n","            \n","        elif self.model_name == 'efficientnet-b0':\n","            model = models.efficientnet_b0(pretrained=True)\n","            model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            model.classifier[1] = nn.Linear(in_features=1280, out_features=self.num_classes, bias=True)\n","            \n","        elif self.model_name == 'efficientnet-b1':\n","            model = models.efficientnet_b1(pretrained=True)\n","            first_conv_layer = model.features[0][0]\n","            model.features[0][0] = torch.nn.Conv2d(1, first_conv_layer.out_channels, \n","                                      kernel_size=first_conv_layer.kernel_size, \n","                                      stride=first_conv_layer.stride, \n","                                      padding=first_conv_layer.padding, bias=False)\n","            model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, self.num_classes)\n","          \n","        elif self.model_name == 'efficientnet_v2_l':\n","            model = models.efficientnet_v2_l(weights='IMAGENET1K_V1')\n","            model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, self.num_classes, bias=True)\n","            \n","        elif self.model_name == 'resnet-50':\n","            model = models.resnet50(pretrained=True)\n","            model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","            model.fc = nn.Linear(in_features=2048, out_features=self.num_classes, bias=True)\n","            \n","        print(f'load {self.model_name} model with ImageNet weights and {self.num_classes} classes')\n","        return model\n","    \n","    def load_kylberg_weights(self):\n","        \n","        weights_path = hf_hub_download(repo_id=self.repo_id, filename=self.filename)\n","        state_dict = torch.load(weights_path)\n","        \n","        if self.model_name == 'mobilenet-v2':\n","            model = models.mobilenet_v2(weights=None)\n","            model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            model.classifier[1] = nn.Linear(model.last_channel, 28)\n","            model.load_state_dict(state_dict)\n","            model.classifier[1] = nn.Linear(model.last_channel, self.num_classes)\n","        print(f'load {self.model_name} model with Kylberg weights')\n","        return model\n","    \n","model = LozzModel(model_name='mobilenet-v2', repo_id='danzzzll/mobilenet-v2-textures', \n","                  filename='mob-v2_trainKylberg_finetuneLoz-2class.pth', \n","                  num_classes=NUM_CLASSES\n","                )\n","model = model.load_model()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:06.767232Z","iopub.status.busy":"2024-04-18T10:41:06.766956Z","iopub.status.idle":"2024-04-18T10:41:06.774599Z","shell.execute_reply":"2024-04-18T10:41:06.773747Z","shell.execute_reply.started":"2024-04-18T10:41:06.767208Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.AdamW(model.parameters())\n","\n","milestones = [12, 15, 26]\n","gamma = 0.3\n","exp_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:06.775999Z","iopub.status.busy":"2024-04-18T10:41:06.775692Z","iopub.status.idle":"2024-04-18T10:41:40.986416Z","shell.execute_reply":"2024-04-18T10:41:40.985450Z","shell.execute_reply.started":"2024-04-18T10:41:06.775969Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.init(\n","    project=\"kylberg with lozz\",\n","    name='experiment 10.4',\n","    config={\n","        \"architecture\": \"mobilenet\",\n","        \"dataset\": \"lozz\",\n","        \"epochs\": 30,\n","        \"fragments\": 9,\n","        \"central\": True,\n","        \"batch_size\": 32,\n","        \"classes\": 5,\n","        \"size\": 224,\n","#         \"augmentations_kylberg\": \"\"\"\n","#             1. Горизонтальное отображение\n","#             2. Поворот \n","#             3. Вертикальное отображение\n","#             4. Случайное изменение яркости и контраста\n","#             5. Гауссовский шум\n","#             6. Соль и перец, salt=0.4\n","#             7. Нормализация\n","#         \"\"\",\n","        \"augmentations_lozz\": \"\"\"\n","           1. Горизонтальное отображение\n","           2. Поворот\n","           3. Соль и перец\n","           4. Нормализация\n","           5. Разделение на 9 фрагментов по 224x224\n","        \"\"\",\n","#         \"augmentation_lozz\": \"9 фрагментов, больше ничего\",\n","        \"notes\": \"5 классов Loz \",\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:40.988812Z","iopub.status.busy":"2024-04-18T10:41:40.988157Z","iopub.status.idle":"2024-04-18T10:41:41.012926Z","shell.execute_reply":"2024-04-18T10:41:41.011952Z","shell.execute_reply.started":"2024-04-18T10:41:40.988758Z"},"trusted":true},"outputs":[],"source":["# Функция для обучения и оценки модели\n","\n","train_loss = []\n","train_acc = []\n","train_full = []\n","test_loss = []\n","test_acc = []\n","test_full = []\n","\n","def train_and_validate_lozz(epoch, model, train_dataloader_lozz, valid_dataloader_lozz):\n","                                                   ### train\n","    \n","    print(f'EPOCH: {epoch + 1}')\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    fragments_train = MultiDict()\n","    model.train()\n","    for batch_idx, (data, image_name, target) in tqdm(enumerate(train_dataloader_lozz)):\n","        target = target.type(torch.LongTensor).to(device)\n","        data = data.unsqueeze(1)\n","        data, target = data.to(device).float(), target.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        preds = outputs.argmax(dim=1)\n","        running_acc += (preds == target).float().mean().item()\n","        \n","        # quality on full images\n","        for n, pred in zip(image_name, preds):\n","            fragments_train.add(n, pred.item()) \n","    \n","    result_train = most_common_class_per_key(fragments_train)\n","    train_full.append(accuracy_full(result_train, train_loz))\n","    train_loss.append(running_loss / len(train_dataloader_lozz))\n","    train_acc.append(running_acc / len(train_dataloader_lozz))\n","    \n","    print(f\"Epoch {epoch+1}, Train Loss: {train_loss[-1]:.3f}, Train Acc: {train_acc[-1]:.3f}, Train Full Images Acc: {train_full[-1]:.3f}\")\n","    exp_lr_scheduler.step()\n","    \n","                                                ### validate\n","\n","    model.eval()\n","    all_preds = [] \n","    all_targets = [] \n","    fragments_test = MultiDict()\n","#     id2label = {0: 'GP',1: 'G'} #, 2: 'M', 3: 'T',4: 'clear'}a\n","    id2label = {v: k for k, v in label2id_loz.items()}\n","    with torch.no_grad():\n","        running_acc = 0.0\n","        for batch_idx, (data, image_name, target) in enumerate(valid_dataloader_lozz):\n","            target = target.type(torch.LongTensor).to(device)\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device).float(), target.to(device)\n","\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            running_loss += loss.item()\n","            preds = outputs.argmax(dim=1)\n","            running_acc += (preds == target).float().mean().item()\n","\n","            all_targets.extend(target.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","            \n","            # quality on full images\n","            for n, pred in zip(image_name, preds):\n","                fragments_test.add(n, pred.item())\n","    \n","    result_test = most_common_class_per_key(fragments_test)\n","    test_full.append(accuracy_full(result_test, valid_loz))\n","    test_loss.append(running_loss / len(valid_dataloader_lozz))\n","    test_acc.append(running_acc / len(valid_dataloader_lozz))\n","    \n","    print(f\"Epoch {epoch+1}, Valid Loss: {test_loss[-1]:.3f}, Valid Acc: {test_acc[-1]:.3f}, Valid Full Images Acc: {test_full[-1]:.3f}\")\n","    \n","    targets_labels = np.array([id2label[id] for id in all_targets])\n","    preds_labels = np.array([id2label[id] for id in all_preds])\n","    cm = confusion_matrix(targets_labels, preds_labels, labels=list(id2label.values()))\n","    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    labels = list(id2label.values())\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=labels)\n","    disp.plot()\n","    plt.title('Normalized Confusion Matrix')\n","    plt.show()\n","    \n","    wandb.log({\n","        \"train_acc\": train_acc[-1],\n","        \"train_loss\": train_loss[-1],\n","        \"train_full\": train_full[-1] / 100,\n","        \"valid_acc\": test_acc[-1],\n","        \"valid_loss\": test_loss[-1],\n","        \"valid_full\": test_full[-1] / 100\n","    })\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:41.014791Z","iopub.status.busy":"2024-04-18T10:41:41.014399Z","iopub.status.idle":"2024-04-18T10:41:41.031157Z","shell.execute_reply":"2024-04-18T10:41:41.030193Z","shell.execute_reply.started":"2024-04-18T10:41:41.014737Z"},"trusted":true},"outputs":[],"source":["def get_predictions(dataloader, model=model):\n","    \"\"\"\n","    возвращает MultiDict, в котором каждому названию картинки соответствует несколько значений\n","    это предсказания для фрагментов данного изображения\n","    для каждого изображения будет строчек столько, на сколько фрагментов разбиваем это изображение\n","    \"\"\"\n","    fragments = MultiDict()\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (data, name, target) in enumerate(dataloader):\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device), target.to(device)\n","            data = data.float()\n","            outputs = model.to(device)(data)\n","            preds = outputs.argmax(dim=1)\n","            \n","            for n, pred in zip(name, preds):\n","                fragments.add(n, pred.item())\n","    return fragments\n","\n","from collections import Counter\n","\n","def most_common_class_per_key(multidict):\n","    \"\"\"\n","    Получает MultiDict на вход и подсчитывает для одного изображения самый частый предсказанный класс\n","    Выдает словарь, с названием изображения и самым частым классом\n","    \"\"\"\n","    result = {}\n","    keys = set(multidict.keys())\n","    \n","    for key in keys:\n","        values = multidict.getall(key)\n","        count = Counter(values)  \n","        most_common_class, _ = count.most_common(1)[0]\n","        result[key] = most_common_class\n","        \n","    return result\n","\n","def accuracy_full(result: dict, df:pd.DataFrame):  \n","    \"\"\"\n","    result - словарь, где каждому пути к изображению сопоставляется самый часто встречаемый класс\n","    return accuracy - между предсказанными значениями и истинными\n","    \"\"\"\n","    true_val = 0.0\n","    for key, value in result.items():\n","        y_true = df.loc[df['image_name'] == key]['class'].item()\n","        y_pred = result[key]\n","#         print(y_true)\n","#         print(y_pred)\n","        if y_true == y_pred:\n","            true_val += 1\n","    accuracy = round(true_val / len(result) * 100, 3)\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T10:41:41.032800Z","iopub.status.busy":"2024-04-18T10:41:41.032437Z","iopub.status.idle":"2024-04-18T12:26:21.360556Z","shell.execute_reply":"2024-04-18T12:26:21.359602Z","shell.execute_reply.started":"2024-04-18T10:41:41.032750Z"},"trusted":true},"outputs":[],"source":["best_loss = float('inf')\n","epochs_without_improvement = 0\n","early_stopping_threshold = 4\n","\n","for epoch in range(30):\n","    model = train_and_validate_lozz(epoch, model, train_dataloader_loz, valid_dataloader_loz)\n","    \n","    if test_loss[-1] < best_loss:\n","        best_loss = test_loss[-1]\n","        best_weights = model.state_dict()\n","        print(f'Best weights on {epoch + 1} EPOCH')\n","        print()\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","        \n","    if epochs_without_improvement >= early_stopping_threshold:\n","        print(\"Early stopping triggered after {} epochs without improvement.\".format(epochs_without_improvement))\n","        break\n","model.load_state_dict(best_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T09:40:23.841961Z","iopub.status.busy":"2024-04-18T09:40:23.841255Z","iopub.status.idle":"2024-04-18T09:40:27.405779Z","shell.execute_reply":"2024-04-18T09:40:27.404922Z","shell.execute_reply.started":"2024-04-18T09:40:23.841925Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1917397,"sourceId":3150785,"sourceType":"datasetVersion"},{"datasetId":3400341,"sourceId":8009145,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
