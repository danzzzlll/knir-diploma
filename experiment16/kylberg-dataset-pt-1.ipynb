{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:11.196328Z","iopub.status.busy":"2024-04-01T15:47:11.195565Z","iopub.status.idle":"2024-04-01T15:47:22.168577Z","shell.execute_reply":"2024-04-01T15:47:22.167665Z","shell.execute_reply.started":"2024-04-01T15:47:11.196287Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from PIL import Image\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from torch.utils.data import Dataset, DataLoader, Sampler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision.models as models\n","from sklearn.model_selection import train_test_split\n","\n","import cv2\n","\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.171914Z","iopub.status.busy":"2024-04-01T15:47:22.170314Z","iopub.status.idle":"2024-04-01T15:47:22.181217Z","shell.execute_reply":"2024-04-01T15:47:22.180409Z","shell.execute_reply.started":"2024-04-01T15:47:22.171883Z"},"trusted":true},"outputs":[],"source":["# fix seeds\n","DEFAULT_RANDOM_SEED = 42\n","import random\n","\n","def set_all_seeds(seed=DEFAULT_RANDOM_SEED):\n","\n","    # python's seeds\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","    # torch's seeds\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_all_seeds(seed=DEFAULT_RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.182886Z","iopub.status.busy":"2024-04-01T15:47:22.182522Z","iopub.status.idle":"2024-04-01T15:47:22.194669Z","shell.execute_reply":"2024-04-01T15:47:22.193884Z","shell.execute_reply.started":"2024-04-01T15:47:22.182854Z"},"trusted":true},"outputs":[],"source":["directory_path = '/kaggle/input/kylberg-texture-dataset'\n","\n","# Получаем список всех папок в директории\n","folder_names = [name for name in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, name))]\n","# создание классов\n","label2id = {} \n","for ind, name in enumerate(folder_names):\n","    label2id[name] = ind\n","id2label = {v:k for k, v in label2id.items()} "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.196932Z","iopub.status.busy":"2024-04-01T15:47:22.196664Z","iopub.status.idle":"2024-04-01T15:47:22.975101Z","shell.execute_reply":"2024-04-01T15:47:22.974345Z","shell.execute_reply.started":"2024-04-01T15:47:22.196909Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","root_path = Path(directory_path)\n","\n","data = {'class_name': [], 'image_name': []}\n","\n","for class_folder in tqdm(root_path.iterdir()):\n","    if class_folder.is_dir():  # Проверяем, что это директория\n","        for image_file in class_folder.iterdir():\n","            if image_file.is_file():  # Проверяем, что это файл\n","                data['class_name'].append(class_folder.name)\n","                data['image_name'].append(image_file.name)\n","\n","# Создаем датафрейм названий и классов изображений\n","df = pd.DataFrame(data)\n","df['class'] = df['class_name'].map(label2id)\n","\n","# делим на train - test выборки в равном соотношении\n","train, test = train_test_split(df, random_state=42, shuffle=True, stratify=df['class'])\n","train = train.reset_index(drop=True)\n","test = test.reset_index(drop=True)\n","y_test = test['class'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.976880Z","iopub.status.busy":"2024-04-01T15:47:22.976595Z","iopub.status.idle":"2024-04-01T15:47:22.983970Z","shell.execute_reply":"2024-04-01T15:47:22.983029Z","shell.execute_reply.started":"2024-04-01T15:47:22.976857Z"},"trusted":true},"outputs":[],"source":["os.path.join(train.iloc[0]['class_name'], train.iloc[0]['image_name'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.985431Z","iopub.status.busy":"2024-04-01T15:47:22.985143Z","iopub.status.idle":"2024-04-01T15:47:22.994360Z","shell.execute_reply":"2024-04-01T15:47:22.993491Z","shell.execute_reply.started":"2024-04-01T15:47:22.985408Z"},"trusted":true},"outputs":[],"source":["class KylbergDataset(Dataset):\n","    def __init__(self, df: pd.DataFrame, folder_path: str, transform=None):\n","        self.df = df\n","        self.transform = transform\n","        self.folder_path = folder_path\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, idx):\n","        \n","        path_to_image = os.path.join(self.folder_path, self.df.iloc[idx]['class_name'], self.df.iloc[idx]['image_name'])\n","        image = Image.open(path_to_image).convert('L')\n","        image_np = np.array(image)\n","        \n","#         fragments = cut_fragments(image=image_np, mode=self.mode, n=self.n, size=self.size)\n","#         fragment = fragments[fragment_idx]\n","        \n","        # нормализуем фрагмент\n","#         max_value = np.max(image_np)\n","        image_np = image_np / 255.0\n","        \n","        if self.transform:\n","            image_np = self.transform(image=image_np)['image']\n","        \n","        image_t = torch.tensor(image_np, dtype=torch.float32)\n","        label = self.df.iloc[idx]['class']\n","\n","        return image_t, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:22.996062Z","iopub.status.busy":"2024-04-01T15:47:22.995493Z","iopub.status.idle":"2024-04-01T15:47:23.009249Z","shell.execute_reply":"2024-04-01T15:47:23.008309Z","shell.execute_reply.started":"2024-04-01T15:47:22.996032Z"},"trusted":true},"outputs":[],"source":["class SaltAndPepper(A.ImageOnlyTransform):\n","    def __init__(self, p=1., salt_ratio=0.5, amount=0.0008, always_apply=True):\n","        super().__init__(always_apply, p)\n","        self.salt_ratio = salt_ratio\n","        self.amount = amount\n","\n","    def apply(self, image, **params):\n","        image_copy = np.copy(image)  # создание копии изображения\n","\n","        num_salt = np.ceil(self.amount * image.size * self.salt_ratio)\n","        coords_salt = [np.random.randint(0, i - 1, int(num_salt)) for i in image_copy.shape]\n","        image_copy[coords_salt[0], coords_salt[1]] = 1\n","\n","        num_pepper = np.ceil(self.amount * image.size * (1.0 - self.salt_ratio))\n","        coords_pepper = [np.random.randint(0, i - 1, int(num_pepper)) for i in image_copy.shape]\n","        image_copy[coords_pepper[0], coords_pepper[1]] = 0\n","\n","        return image_copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.010523Z","iopub.status.busy":"2024-04-01T15:47:23.010278Z","iopub.status.idle":"2024-04-01T15:47:23.021550Z","shell.execute_reply":"2024-04-01T15:47:23.020670Z","shell.execute_reply.started":"2024-04-01T15:47:23.010502Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=.3),\n","#     A.RandomBrightnessContrast(p=1, contrast_limit=(.2), brightness_by_max=True, brightness_limit=(.2)),\n","    A.Rotate(limit=30, p=.3),\n","#     A.GaussianBlur(p=1, blur_limit=(1,3)),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=200, max_height=3, max_width=3),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=0, max_height=3, max_width=3),\n","    A.GaussNoise(var_limit=(10.0), p=1), #белый шум\n","#     SaltAndPepper(salt_ratio=0.4),\n","#     A.ElasticTransform(alpha=2, sigma=20, alpha_affine=10, p=.4),\n","])\n","\n","# test_transform = A.Compose([\n","    \n","    \n","# ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.022831Z","iopub.status.busy":"2024-04-01T15:47:23.022561Z","iopub.status.idle":"2024-04-01T15:47:23.034854Z","shell.execute_reply":"2024-04-01T15:47:23.034011Z","shell.execute_reply.started":"2024-04-01T15:47:23.022800Z"},"trusted":true},"outputs":[],"source":["train_dataset = KylbergDataset(train, directory_path, train_transform)\n","test_dataset = KylbergDataset(test, directory_path)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, drop_last=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.037463Z","iopub.status.busy":"2024-04-01T15:47:23.037184Z","iopub.status.idle":"2024-04-01T15:47:23.711227Z","shell.execute_reply":"2024-04-01T15:47:23.710453Z","shell.execute_reply.started":"2024-04-01T15:47:23.037437Z"},"trusted":true},"outputs":[],"source":["NUM_CLASSES = len(label2id)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","mobilenet_v2_model = models.mobilenet_v2(pretrained=True)\n","mobilenet_v2_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","mobilenet_v2_model.classifier[1] = nn.Linear(mobilenet_v2_model.last_channel, NUM_CLASSES)\n","mobilenet_v2_model = mobilenet_v2_model.to(device)\n","\n","if torch.cuda.device_count() > 1:\n","    mobilenet_v2_model = torch.nn.DataParallel(mobilenet_v2_model)\n","    \n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(mobilenet_v2_model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.712864Z","iopub.status.busy":"2024-04-01T15:47:23.712419Z","iopub.status.idle":"2024-04-01T15:47:23.717904Z","shell.execute_reply":"2024-04-01T15:47:23.716805Z","shell.execute_reply.started":"2024-04-01T15:47:23.712828Z"},"trusted":true},"outputs":[],"source":["# criterion = nn.CrossEntropyLoss()\n","# criterion = FocalLoss(alpha=.8)\n","\n","# optimizer = torch.optim.AdamW(mobilenet_v2_model.parameters())\n","# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.6)\n","\n","# milestones = [12, 15, 26]\n","# gamma = 0.3\n","# exp_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.719934Z","iopub.status.busy":"2024-04-01T15:47:23.719255Z","iopub.status.idle":"2024-04-01T15:47:23.734963Z","shell.execute_reply":"2024-04-01T15:47:23.734067Z","shell.execute_reply.started":"2024-04-01T15:47:23.719901Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","train_acc = []\n","\n","test_loss = []\n","test_acc = []\n","\n","def train_and_validate(epoch, model):\n","                                                ### train\n","    print(f'EPOCH: {epoch + 1}')\n","    \n","    running_loss = 0.0\n","    running_acc = 0.0\n","    model.train()\n","    for batch_idx, (data, target) in tqdm(enumerate(train_dataloader)):\n","        target = target.type(torch.LongTensor).to(device)\n","        data = data.unsqueeze(1)\n","        data, target = data.to(device).float(), target.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        preds = outputs.argmax(dim=1)\n","        running_acc += (preds == target).float().mean().item()\n","        \n","#         if batch_idx % 200 == 0:\n","#             random_img = data.cpu().numpy()[np.random.randint(data.size(0))][0]\n","#             plt.imshow(random_img, cmap='gray')\n","#             plt.title(\"Random Image from Batch\")\n","#             plt.axis('off')\n","#             plt.show()\n","    \n","    train_loss.append(running_loss / len(train_dataloader))\n","    train_acc.append(running_acc / len(train_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Train Loss: {train_loss[-1]:.3f}, Train Acc: {train_acc[-1]:.3f}\")\n","#     exp_lr_scheduler.step()\n","    \n","                                                ### validate\n","\n","    model.eval()\n","    all_preds = [] \n","\n","    with torch.no_grad():\n","        eval_acc = 0.0\n","        eval_loss = 0.0\n","        for batch_idx, (data, target) in enumerate(test_dataloader):\n","            target = target.type(torch.LongTensor).to(device)\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device).float(), target.to(device)\n","\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            eval_loss += loss.item()\n","            preds = outputs.argmax(dim=1)\n","            eval_acc += (preds == target).float().mean().item()\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            \n","    \n","    test_loss.append(eval_loss / len(test_dataloader))\n","    test_acc.append(eval_acc / len(test_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Test Loss: {test_loss[-1]:.3f}, Test Acc: {test_acc[-1]:.3f}\")\n","    print()\n","#     cm = confusion_matrix(all_targets, all_preds)\n","#     disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","#     disp.plot()\n","#     plt.show()\n","    \n","#     wandb.log({\n","#         \"train_acc\": train_acc[-1],\n","#         \"train_loss\": train_loss[-1],\n","#         \"train_full\": train_full[-1] / 100,\n","#         \"valid_acc\": test_acc[-1],\n","#         \"valid_loss\": test_loss[-1],\n","#         \"valid_full\": test_full[-1] / 100\n","#     })\n","    \n","    return train_loss, train_acc, test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:47:23.736466Z","iopub.status.busy":"2024-04-01T15:47:23.736149Z","iopub.status.idle":"2024-04-01T15:56:37.092836Z","shell.execute_reply":"2024-04-01T15:56:37.091570Z","shell.execute_reply.started":"2024-04-01T15:47:23.736440Z"},"trusted":true},"outputs":[],"source":["best_loss = float('inf')\n","epochs_without_improvement = 0\n","early_stopping_threshold = 5\n","\n","for epoch in range(10):\n","    train_loss, train_acc, test_loss, test_acc = train_and_validate(epoch, mobilenet_v2_model)\n","    \n","    if test_loss[-1] < best_loss:\n","        best_loss = test_loss[-1]\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","        \n","    if epochs_without_improvement >= early_stopping_threshold:\n","        print(\"Early stopping triggered after {} epochs without improvement.\".format(epochs_without_improvement))\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# save and load model with huggingface repo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:58:53.449029Z","iopub.status.busy":"2024-04-01T15:58:53.448651Z","iopub.status.idle":"2024-04-01T15:58:53.504876Z","shell.execute_reply":"2024-04-01T15:58:53.504124Z","shell.execute_reply.started":"2024-04-01T15:58:53.449000Z"},"trusted":true},"outputs":[],"source":["torch.save(mobilenet_v2_model.state_dict(), 'mobilenet-v2-textures.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:09:08.343822Z","iopub.status.busy":"2024-04-01T16:09:08.342785Z","iopub.status.idle":"2024-04-01T16:09:09.748975Z","shell.execute_reply":"2024-04-01T16:09:09.747987Z","shell.execute_reply.started":"2024-04-01T16:09:08.343784Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import upload_file, HfFolder, notebook_login, hf_hub_download\n","\n","notebook_login()\n","\n","# Assuming you've stored your Hugging Face token as a Kaggle secret\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient()\n","# hf_token = user_secrets.get_secret(\"huggingface_token\")\n","\n","repo_name = \"danzzzll/mobilenet-v2-textures\"  # Replace with your Hugging Face Hub repo\n","model_file_path = '/kaggle/working/mobilenet-v2-textures.pth'\n","\n","# Upload the model file\n","upload_file(\n","    path_or_fileobj=model_file_path,\n","    path_in_repo=\"mobilenet-v2-textures.pth\",  # Path where the file will be stored in your repo\n","    repo_id=repo_name,\n","#     token=hf_token,\n","    repo_type=\"model\"\n",")\n","\n","print(f\"Model successfully uploaded to: https://huggingface.co/{repo_name}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:22:15.446516Z","iopub.status.busy":"2024-04-01T16:22:15.446099Z","iopub.status.idle":"2024-04-01T16:22:15.610432Z","shell.execute_reply":"2024-04-01T16:22:15.609231Z","shell.execute_reply.started":"2024-04-01T16:22:15.446487Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","from huggingface_hub import upload_file, HfFolder, notebook_login, hf_hub_download\n","from collections import OrderedDict\n","\n","\n","NUM_CLASSES = len(class_dict)\n","\n","repo_id = 'danzzzll/mobilenet-v2-textures'\n","filename = 'mobilenet-v2-textures.pth'\n","\n","def loading_weights(repo_id, filename):\n","    weights_path = hf_hub_download(repo_id=repo_id, filename=filename)\n","    \n","    model = models.mobilenet_v2(weights=None)\n","    model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    model.classifier[1] = nn.Linear(model.last_channel, 28)\n","\n","    state_dict = torch.load(weights_path, map_location='cpu')\n","    \n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        name = k[7:] if k.startswith('module.') else k  # remove `module.` prefix if exists\n","        new_state_dict[name] = v\n","\n","    model.load_state_dict(new_state_dict)\n","    model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n","\n","    if torch.cuda.device_count() > 1:\n","        model = torch.nn.DataParallel(model)\n","    \n","    model = model.to(device)\n","    return model\n","\n","model = loading_weights(repo_id, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:29:46.818932Z","iopub.status.busy":"2024-04-01T16:29:46.818483Z","iopub.status.idle":"2024-04-01T16:29:53.442306Z","shell.execute_reply":"2024-04-01T16:29:53.441122Z","shell.execute_reply.started":"2024-04-01T16:29:46.818895Z"},"trusted":true},"outputs":[],"source":["def evaluation(model):\n","    model.eval()\n","    with torch.no_grad():\n","        running_acc = 0.0\n","        running_loss = 0.0\n","        for batch_idx, (data, target) in enumerate(test_dataloader):\n","            target = target.type(torch.LongTensor).to(device)\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device).float(), target.to(device)\n","\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            running_loss += loss.item()\n","            preds = outputs.argmax(dim=1)\n","            running_acc += (preds == target).float().mean().item()\n","\n","    return running_acc / len(test_dataloader)\n","\n","evaluation(new_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:45:35.041370Z","iopub.status.busy":"2024-04-01T16:45:35.040474Z","iopub.status.idle":"2024-04-01T16:45:35.046995Z","shell.execute_reply":"2024-04-01T16:45:35.046070Z","shell.execute_reply.started":"2024-04-01T16:45:35.041325Z"},"trusted":true},"outputs":[],"source":["def inference(model, image, id2label):\n","    model.eval()\n","    image = image.unsqueeze(0).unsqueeze(0)\n","    print(image.shape)\n","    outputs = model(image)\n","    preds = outputs.argmax()\n","    clas = preds.item()\n","    \n","    return id2label.get(clas)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
