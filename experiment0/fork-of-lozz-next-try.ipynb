{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:01:59.842325Z","iopub.status.busy":"2023-11-28T09:01:59.841989Z","iopub.status.idle":"2023-11-28T09:02:13.358418Z","shell.execute_reply":"2023-11-28T09:02:13.357407Z","shell.execute_reply.started":"2023-11-28T09:01:59.842295Z"},"trusted":true},"outputs":[],"source":["!pip install multidict -q #efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:13.360699Z","iopub.status.busy":"2023-11-28T09:02:13.360408Z","iopub.status.idle":"2023-11-28T09:02:22.890803Z","shell.execute_reply":"2023-11-28T09:02:22.889922Z","shell.execute_reply.started":"2023-11-28T09:02:13.360674Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","from PIL import Image\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# from efficientnet_pytorch import EfficientNet\n","from torch.utils.data import Dataset, DataLoader, Sampler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision.models as models\n","\n","from numba import jit\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm.auto import tqdm\n","from multidict import MultiDict\n","\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:22.892344Z","iopub.status.busy":"2023-11-28T09:02:22.891908Z","iopub.status.idle":"2023-11-28T09:02:22.905742Z","shell.execute_reply":"2023-11-28T09:02:22.904840Z","shell.execute_reply.started":"2023-11-28T09:02:22.892309Z"},"trusted":true},"outputs":[],"source":["DEFAULT_RANDOM_SEED = 42\n","import random\n","import numpy as np\n","\n","\n","def set_all_seeds(seed=DEFAULT_RANDOM_SEED):\n","\n","    # python's seeds\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","    # torch's seeds\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_all_seeds(seed=DEFAULT_RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:22.908105Z","iopub.status.busy":"2023-11-28T09:02:22.907837Z","iopub.status.idle":"2023-11-28T09:02:22.914940Z","shell.execute_reply":"2023-11-28T09:02:22.914148Z","shell.execute_reply.started":"2023-11-28T09:02:22.908081Z"},"trusted":true},"outputs":[],"source":["# для получения label для каждого файла\n","class_dict = {\n","    'GP': 0, 'G': 1, 'M': 2, 'T': 3, 'clear': 4 # выкинуть один класс - clear\n","}\n","\n","# class_dict = {\n","#     '-20':0, '-25':1, '-30':2, '-35':3\n","# }\n","\n","def get_class_from_path(path, class_dict=class_dict):\n","    for key in class_dict:\n","        if key in path:\n","            return class_dict[key]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:22.916067Z","iopub.status.busy":"2023-11-28T09:02:22.915813Z","iopub.status.idle":"2023-11-28T09:02:22.991873Z","shell.execute_reply":"2023-11-28T09:02:22.990745Z","shell.execute_reply.started":"2023-11-28T09:02:22.916045Z"},"trusted":true},"outputs":[],"source":["root_dir = '/kaggle/input/lozzzz/all_images'\n","image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n","\n","new_img_files = []\n","labels = []\n","for elem in image_files:\n","    for key in class_dict:\n","        if key in elem:\n","            labels.append(class_dict[key])\n","            new_img_files.append(elem)\n","            break\n","        else:\n","            continue"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:22.993516Z","iopub.status.busy":"2023-11-28T09:02:22.992997Z","iopub.status.idle":"2023-11-28T09:02:23.004440Z","shell.execute_reply":"2023-11-28T09:02:23.003544Z","shell.execute_reply.started":"2023-11-28T09:02:22.993484Z"},"trusted":true},"outputs":[],"source":["train_paths, valid_paths = train_test_split(new_img_files, random_state=42, shuffle=True, train_size=0.7, stratify=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.005868Z","iopub.status.busy":"2023-11-28T09:02:23.005584Z","iopub.status.idle":"2023-11-28T09:02:23.013214Z","shell.execute_reply":"2023-11-28T09:02:23.012436Z","shell.execute_reply.started":"2023-11-28T09:02:23.005844Z"},"trusted":true},"outputs":[],"source":["labels_train = []\n","for elem in train_paths:\n","    for key in class_dict:\n","        if key in elem:\n","            labels_train.append(class_dict[key])\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.014489Z","iopub.status.busy":"2023-11-28T09:02:23.014196Z","iopub.status.idle":"2023-11-28T09:02:23.126397Z","shell.execute_reply":"2023-11-28T09:02:23.125722Z","shell.execute_reply.started":"2023-11-28T09:02:23.014466Z"},"trusted":true},"outputs":[],"source":["from collections import Counter\n","Counter(labels_train)\n","\n","class_counts = [106, 104, 89, 99, 59]\n","class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n","class_weights /= class_weights.sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.127506Z","iopub.status.busy":"2023-11-28T09:02:23.127282Z","iopub.status.idle":"2023-11-28T09:02:23.307277Z","shell.execute_reply":"2023-11-28T09:02:23.306593Z","shell.execute_reply.started":"2023-11-28T09:02:23.127486Z"},"trusted":true},"outputs":[],"source":["@jit(nopython=True)\n","def cut_fragments(image, mode, n, size):\n","    height, width = image.shape[:2]\n","    fragments = []\n","    if mode == 'central':\n","        for i in range(n):\n","            for j in range(n):\n","                left = (width / n) * i\n","                upper = (height / n) * j\n","                right = left + size\n","                lower = upper + size\n","                fragment = image[int(upper):int(lower), int(left):int(right)]\n","                fragments.append(fragment)\n","    elif mode == 'random':\n","        for _ in range(n):\n","            left = random.randint(0, width - size)\n","            upper = random.randint(0, height - size)\n","            right = left + size\n","            lower = upper + size\n","            fragment = image[int(upper):int(lower), int(left):int(right)]\n","            fragments.append(fragment)\n","    return fragments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.311282Z","iopub.status.busy":"2023-11-28T09:02:23.310957Z","iopub.status.idle":"2023-11-28T09:02:23.322106Z","shell.execute_reply":"2023-11-28T09:02:23.321238Z","shell.execute_reply.started":"2023-11-28T09:02:23.311259Z"},"trusted":true},"outputs":[],"source":["class LozDataset(Dataset):\n","    def __init__(self, root_dir, image_files, mode: str = 'central', n: int = 3, size: int = 224, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_files = [os.path.join(self.root_dir, image_file) for image_file in image_files]\n","        self.mode = mode\n","        self.n = n\n","        self.size = size\n","        \n","    def __len__(self):\n","        if self.mode == 'central':  \n","            return len(self.image_files) * self.n * self.n\n","        else:\n","            return len(self.image_files) * self.n\n","\n","    def __getitem__(self, idx):\n","        if self.mode:\n","            fragments_per_image = self.n * self.n\n","        else:\n","            fragments_per_image = self.n\n","\n","        image_idx = idx // fragments_per_image\n","        fragment_idx = idx % fragments_per_image\n","        \n","        img_name = self.image_files[image_idx]\n","        image = Image.open(img_name).convert('L')\n","        image_np = np.array(image)\n","        \n","        fragments = cut_fragments(image=image_np, mode=self.mode, n=self.n, size=self.size)\n","        fragment = fragments[fragment_idx]\n","        \n","        # нормализуем фрагмент\n","#         max_value = np.max(fragment)\n","#         fragment = fragment / max_value\n","#         fragment = cut_percentiles(fragment)\n","#         fragment = apply_bilateral_filter_to_normalized(fragment)\n","        \n","        if self.transform:\n","            fragment = self.transform(image=fragment)['image']\n","        \n","        label = get_class_from_path(img_name)\n","        image_t = torch.tensor(fragment, dtype=torch.float32)\n","\n","        return image_t, img_name, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.323832Z","iopub.status.busy":"2023-11-28T09:02:23.323447Z","iopub.status.idle":"2023-11-28T09:02:23.338338Z","shell.execute_reply":"2023-11-28T09:02:23.337684Z","shell.execute_reply.started":"2023-11-28T09:02:23.323796Z"},"trusted":true},"outputs":[],"source":["# соль и перец\n","class SaltAndPepper(A.ImageOnlyTransform):\n","    def __init__(self, p=1., salt_ratio=0.5, amount=0.0008, always_apply=True):\n","        super().__init__(always_apply, p)\n","        self.salt_ratio = salt_ratio\n","        self.amount = amount\n","\n","    def apply(self, image, **params):\n","        image_copy = np.copy(image)  # создание копии изображения\n","\n","        num_salt = np.ceil(self.amount * image.size * self.salt_ratio)\n","        coords_salt = [np.random.randint(0, i - 1, int(num_salt)) for i in image_copy.shape]\n","        image_copy[coords_salt[0], coords_salt[1]] = 1\n","\n","        num_pepper = np.ceil(self.amount * image.size * (1.0 - self.salt_ratio))\n","        coords_pepper = [np.random.randint(0, i - 1, int(num_pepper)) for i in image_copy.shape]\n","        image_copy[coords_pepper[0], coords_pepper[1]] = 0\n","\n","        return image_copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.339887Z","iopub.status.busy":"2023-11-28T09:02:23.339349Z","iopub.status.idle":"2023-11-28T09:02:23.356548Z","shell.execute_reply":"2023-11-28T09:02:23.355864Z","shell.execute_reply.started":"2023-11-28T09:02:23.339847Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=.3),\n","#     A.RandomBrightnessContrast(p=1, contrast_limit=(.2), brightness_by_max=True, brightness_limit=(.2)),\n","    A.Rotate(limit=30, p=.3),\n","#     A.GaussianBlur(p=1, blur_limit=(1,3)),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=200, max_height=3, max_width=3),\n","#     A.CoarseDropout(max_holes=6, p=1., fill_value=0, max_height=3, max_width=3),\n","#     A.GaussNoise(var_limit=(10.0), p=1), #белый шум\n","    SaltAndPepper(salt_ratio=0.4),\n","#     A.ElasticTransform(alpha=2, sigma=20, alpha_affine=10, p=.4),\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.357982Z","iopub.status.busy":"2023-11-28T09:02:23.357720Z","iopub.status.idle":"2023-11-28T09:02:23.369773Z","shell.execute_reply":"2023-11-28T09:02:23.368738Z","shell.execute_reply.started":"2023-11-28T09:02:23.357959Z"},"trusted":true},"outputs":[],"source":["root_dir = '/kaggle/input/lozzzz/all_images'\n","train_dataset = LozDataset(root_dir, train_paths, n=3)\n","valid_dataset = LozDataset(root_dir, valid_paths, n=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.371460Z","iopub.status.busy":"2023-11-28T09:02:23.370883Z","iopub.status.idle":"2023-11-28T09:02:23.379205Z","shell.execute_reply":"2023-11-28T09:02:23.378338Z","shell.execute_reply.started":"2023-11-28T09:02:23.371428Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, drop_last=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=2, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:23.380339Z","iopub.status.busy":"2023-11-28T09:02:23.380078Z","iopub.status.idle":"2023-11-28T09:02:28.509523Z","shell.execute_reply":"2023-11-28T09:02:28.508571Z","shell.execute_reply.started":"2023-11-28T09:02:23.380318Z"},"trusted":true},"outputs":[],"source":["NUM_CLASSES = len(class_dict)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","mobilenet_v2_model = models.mobilenet_v2(pretrained=True)\n","mobilenet_v2_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","mobilenet_v2_model.classifier[1] = nn.Linear(mobilenet_v2_model.last_channel, NUM_CLASSES)\n","mobilenet_v2_model = mobilenet_v2_model.to(device)\n","\n","if torch.cuda.device_count() > 1:\n","    mobilenet_v2_model = torch.nn.DataParallel(mobilenet_v2_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:28.511059Z","iopub.status.busy":"2023-11-28T09:02:28.510762Z","iopub.status.idle":"2023-11-28T09:02:28.519061Z","shell.execute_reply":"2023-11-28T09:02:28.517431Z","shell.execute_reply.started":"2023-11-28T09:02:28.511033Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","# criterion = FocalLoss(alpha=.8)\n","\n","optimizer = torch.optim.AdamW(mobilenet_v2_model.parameters())\n","# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.6)\n","\n","milestones = [12, 15, 26]\n","gamma = 0.3\n","exp_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:02:28.520662Z","iopub.status.busy":"2023-11-28T09:02:28.520329Z","iopub.status.idle":"2023-11-28T09:03:02.644510Z","shell.execute_reply":"2023-11-28T09:03:02.643691Z","shell.execute_reply.started":"2023-11-28T09:02:28.520614Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"first_expirement\",\n","    name='mobilenet: without augmentations and normalizing',\n","    # track hyperparameters and run metadata\n","    config={\n","        \"architecture\": \"mobilenet\",\n","        \"dataset\": \"lozz\",\n","        \"epochs\": 30,\n","        \"fragments\": 9,\n","        \"central\": True,\n","        \"batch_size\": 16,\n","        \"classes\": 5,\n","        \"size\": 224,\n","        \"optimizer\": 'torch.optim.AdamW(mobilenet_v2_model.parameters())',\n","        \"criterion\": 'nn.CrossEntropyLoss(weight=class_weights.to(device))',\n","        \"sheduler\": 'torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=gamma)'\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:03:02.646229Z","iopub.status.busy":"2023-11-28T09:03:02.645853Z","iopub.status.idle":"2023-11-28T09:03:02.666625Z","shell.execute_reply":"2023-11-28T09:03:02.665846Z","shell.execute_reply.started":"2023-11-28T09:03:02.646193Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","train_acc = []\n","train_full = []\n","test_loss = []\n","test_acc = []\n","test_full = []\n","def train_and_validate(epoch, model):\n","                                                ### train\n","    print(f'EPOCH: {epoch + 1}')\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    fragments_train = MultiDict()\n","    model.train()\n","    for batch_idx, (data, name, target) in tqdm(enumerate(train_dataloader)):\n","        target = target.type(torch.LongTensor).to(device)\n","        data = data.unsqueeze(1)\n","        data, target = data.to(device).float(), target.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        preds = outputs.argmax(dim=1)\n","        running_acc += (preds == target).float().mean().item()\n","        \n","        # quality on full images\n","        for n, pred in zip(name, preds):\n","            fragments_train.add(n, pred.item())\n","        \n","#         if batch_idx % 150 == 0:\n","#             random_img = data.cpu().numpy()[np.random.randint(data.size(0))][0]\n","#             plt.imshow(random_img, cmap='gray')\n","#             plt.title(\"Random Image from Batch\")\n","#             plt.axis('off')\n","#             plt.show()\n","    \n","    result_train = most_common_class_per_key(fragments_train)\n","    train_full.append(accuracy_full(result_train))\n","    train_loss.append(running_loss / len(train_dataloader))\n","    train_acc.append(running_acc / len(train_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Train Loss: {train_loss[-1]:.3f}, Train Acc: {train_acc[-1]:.3f}, Train Full Images Acc: {train_full[-1]:.3f}\")\n","    exp_lr_scheduler.step()\n","    \n","                                                ### validate\n","\n","    model.eval()\n","    all_preds = [] \n","    all_targets = [] \n","    fragments_test = MultiDict()\n","    with torch.no_grad():\n","        running_acc = 0.0\n","        for batch_idx, (data, name, target) in enumerate(valid_dataloader):\n","            target = target.type(torch.LongTensor).to(device)\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device).float(), target.to(device)\n","\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            running_loss += loss.item()\n","            preds = outputs.argmax(dim=1)\n","            running_acc += (preds == target).float().mean().item()\n","\n","            all_targets.extend(target.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","            \n","            # quality on full images\n","            for n, pred in zip(name, preds):\n","                fragments_test.add(n, pred.item())\n","    \n","    result_test = most_common_class_per_key(fragments_test)\n","    test_full.append(accuracy_full(result_test))\n","    test_loss.append(running_loss / len(valid_dataloader))\n","    test_acc.append(running_acc / len(valid_dataloader))\n","    \n","    print(f\"Epoch {epoch+1}, Valid Loss: {test_loss[-1]:.3f}, Valid Acc: {test_acc[-1]:.3f}, Valid Full Images Acc: {test_full[-1]:.3f}\")\n","    \n","    cm = confusion_matrix(all_targets, all_preds)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","    disp.plot()\n","    plt.show()\n","    \n","    wandb.log({\n","        \"train_acc\": train_acc[-1],\n","        \"train_loss\": train_loss[-1],\n","        \"train_full\": train_full[-1] / 100,\n","        \"valid_acc\": test_acc[-1],\n","        \"valid_loss\": test_loss[-1],\n","        \"valid_full\": test_full[-1] / 100\n","    })\n","    \n","    return train_loss, train_acc, test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:03:02.668224Z","iopub.status.busy":"2023-11-28T09:03:02.667893Z","iopub.status.idle":"2023-11-28T09:03:02.711617Z","shell.execute_reply":"2023-11-28T09:03:02.710801Z","shell.execute_reply.started":"2023-11-28T09:03:02.668191Z"},"trusted":true},"outputs":[],"source":["def get_predictions(model=mobilenet_v2_model):\n","    \"\"\"\n","    возвращает MultiDict, в котором каждому названию картинки соответствует несколько значений\n","    это предсказания для фрагментов данного изображения\n","    для каждого изображения будет строчек столько, на сколько фрагментов разбиваем это изображение\n","    \"\"\"\n","    fragments = MultiDict()\n","    mobilenet_v2_model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (data, name, target) in enumerate(valid_dataloader):\n","            data = data.unsqueeze(1)\n","            data, target = data.to(device), target.to(device)\n","            data = data.float()\n","            outputs = mobilenet_v2_model.to(device)(data)\n","            preds = outputs.argmax(dim=1)\n","            \n","            for n, pred in zip(name, preds):\n","                fragments.add(n, pred.item())\n","    return fragments\n","\n","from collections import Counter\n","\n","def most_common_class_per_key(multidict):\n","    \"\"\"\n","    Получает MultiDict на вход и подсчитывает для одного изображения самый частый предсказанный класс\n","    Выдает словарь, с названием изображения и самым частым классом\n","    \"\"\"\n","    result = {}\n","    keys = set(multidict.keys())\n","    \n","    for key in keys:\n","        values = multidict.getall(key)\n","        count = Counter(values)  \n","        most_common_class, _ = count.most_common(1)[0]\n","        result[key] = most_common_class\n","        \n","    return result\n","\n","def accuracy_full(result: dict):  \n","    \"\"\"\n","    result - словарь, где каждому пути к изображению сопоставляется самый часто встречаемый класс\n","    return accuracy - между предсказанными значениями и истинными\n","    \"\"\"\n","    true_val = 0.0\n","    for key, value in result.items():\n","        y_true = get_class_from_path(f\"'{key}'\")\n","        y_pred = result[key]\n","        if y_true == y_pred:\n","            true_val += 1\n","    accuracy = round(true_val / len(result) * 100, 3)\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T09:03:02.713795Z","iopub.status.busy":"2023-11-28T09:03:02.712918Z","iopub.status.idle":"2023-11-28T09:45:32.374174Z","shell.execute_reply":"2023-11-28T09:45:32.372906Z","shell.execute_reply.started":"2023-11-28T09:03:02.713761Z"},"trusted":true},"outputs":[],"source":["best_loss = float('inf')\n","epochs_without_improvement = 0\n","early_stopping_threshold = 5\n","\n","for epoch in range(30):\n","    train_loss, train_acc, test_loss, test_acc = train_and_validate(epoch, mobilenet_v2_model)\n","    \n","    if test_loss[-1] < best_loss:\n","        best_loss = test_loss[-1]\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","        \n","    if epochs_without_improvement >= early_stopping_threshold:\n","        print(\"Early stopping triggered after {} epochs without improvement.\".format(epochs_without_improvement))\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T10:46:11.965167Z","iopub.status.busy":"2023-11-08T10:46:11.964751Z","iopub.status.idle":"2023-11-08T10:46:17.713997Z","shell.execute_reply":"2023-11-08T10:46:17.713076Z","shell.execute_reply.started":"2023-11-08T10:46:11.965133Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Оценка результатов для полных картинок"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T08:51:45.025565Z","iopub.status.busy":"2023-11-28T08:51:45.024760Z","iopub.status.idle":"2023-11-28T08:51:45.031233Z","shell.execute_reply":"2023-11-28T08:51:45.030392Z","shell.execute_reply.started":"2023-11-28T08:51:45.025531Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T08:51:45.641553Z","iopub.status.busy":"2023-11-28T08:51:45.640696Z","iopub.status.idle":"2023-11-28T08:51:45.647434Z","shell.execute_reply":"2023-11-28T08:51:45.646319Z","shell.execute_reply.started":"2023-11-28T08:51:45.641519Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fragments = get_predictions()\n","result = most_common_class_per_key(fragments)\n","print(f\"Accuracy для полных картинок: {accuracy_full(result)}%\""]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3400341,"sourceId":6236972,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
